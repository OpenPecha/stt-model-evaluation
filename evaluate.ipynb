{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of STT models\n",
    "\n",
    "Load the benchmark dataset from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install datasets transformers pandas\n",
    "! pip install ipywidgets\n",
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "dataset = load_dataset(\"openpecha/tibetan-voice-benchmark\")\n",
    "df = pd.DataFrame(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 124\n",
    "df.loc[i, 'url'], df.loc[i, 'uni']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Example inference from different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pyewts\n",
    "\n",
    "! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pyewts\n",
    "converter = pyewts.pyewts()\n",
    "\n",
    "print(\"audio url\", df.loc[i, 'url'])\n",
    "\n",
    "print(\"ground truth\", df.loc[i, 'uni'])\n",
    "\n",
    "generator = pipeline(model=\"openpecha/wav2vec2_run8\")\n",
    "opt = generator(df.loc[i, 'url'])\n",
    "inf = opt['text']\n",
    "print(\"openpecha/wav2vec2_run8\", inf)\n",
    "\n",
    "generator = pipeline(model=\"TenzinGayche/whisper-small-3\")\n",
    "opt = generator(df.loc[i, 'url'])\n",
    "inf = opt['text']\n",
    "print(\"TenzinGayche/whisper-small-3\", converter.toUnicode(inf))\n",
    "\n",
    "generator = pipeline(model=\"spsither/whipser-small-r3-aug\")\n",
    "opt = generator(df.loc[i, 'url'])\n",
    "inf = opt['text']\n",
    "print(\"spsither/whipser-small-r3-aug\", converter.toUnicode(inf))\n",
    "\n",
    "generator = pipeline(model=\"spsither/whipser-small-r3-aug-length-penalty_n1\")\n",
    "opt = generator(df.loc[i, 'url'])\n",
    "inf = opt['text']\n",
    "print(\"spsither/whipser-small-r3-aug-length-penalty_n1\", converter.toUnicode(inf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on all the benchmark data with the latest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(model=\"openpecha/wav2vec2_run8\")\n",
    "# generator = pipeline(model=\"TenzinGayche/whisper-small-3\") \n",
    "predictions = []    \n",
    "\n",
    "for url in tqdm(dataset['test']['url']):\n",
    "    # print(url)\n",
    "    opt = generator(url)\n",
    "    predictions.append(opt[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['inf'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyewts\n",
    "\n",
    "# converter = pyewts.pyewts()\n",
    "\n",
    "# def toUnicode(text):\n",
    "#     if type(text) == float:\n",
    "#         return None\n",
    "#     return converter.toUnicode(text)\n",
    "\n",
    "# df['inf'] = df['inf'].map(lambda x : toUnicode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "cer_metric = load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_index = 0\n",
    "print(df.loc[rand_index, 'uni'])\n",
    "print(df.loc[rand_index, 'inf'])\n",
    "cer = cer_metric.compute(references=[df.loc[rand_index, 'uni']], predictions=[df.loc[rand_index, 'inf']])\n",
    "\n",
    "print(cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cer(row):\n",
    "    try:\n",
    "        uni = row['uni']\n",
    "        inf_uni = row['inf']\n",
    "        cer = cer_metric.compute(references=[uni], predictions=[inf_uni])\n",
    "        cer = min(cer, 1.0)\n",
    "        return cer\n",
    "    except:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cer'] = df.apply(lambda row: calculate_cer(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['inf'].str.len().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Average CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cer'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Department wise CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['dept', 'cer']].groupby('dept').mean('cer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we take out MV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['dept'] != 'STT_MV']['cer'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakdown of CS\n",
    "\n",
    "https://github.com/MonlamAI/STT-template/blob/main/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs = df[df['dept'] == 'STT_CS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_correction = {\n",
    "    \"STT_CS-2013-P-D-B08-5-R-01_0007_44457_to_50532\" : \"STT_CS-D-2013-P-D-B08-5-R-01_0007_44457_to_50532\",\n",
    "    \"STT_CS-2013-P-D-B08-5-R-01_0042_289920_to_291996\" : \"STT_CS-D-2013-P-D-B08-5-R-01_0042_289920_to_291996\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01a_0098_1365972_to_1368722\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01a_0098_1365972_to_1368722\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01b_0134_1844125_to_1849525\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01b_0134_1844125_to_1849525\",\n",
    "    \"STT_CS-L-2018_2018_M_M-D_D-B05_B05-3_3-R_R-01B_0118_892189_to_899277\" : \"STT_CS-L-2018/2018-M/M-D/D-B05/B05-3/3-R/R-01B_0118_892189_to_899277\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01c_0009_207925_to_212009\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01c_0009_207925_to_212009\",\n",
    "    \"STT_CS-2013-P-D-B08-5-R-01_0074_513894_to_519842\" : \"STT_CS-D-2013-P-D-B08-5-R-01_0074_513894_to_519842\",\n",
    "    \"STT_CS-L-2018_2018_M_M-D_D-B05_B05-3_3-R_R-01B_0012_92112_to_100229\" : \"STT_CS-L-2018/2018-M/M-D/D-B05/B05-3/3-R/R-01B_0012_92112_to_100229\",\n",
    "    \"STT_CS-2013-P-D-B08-5-R-01_0075_519910_to_529146\" : \"STT_CS-D-2013-P-D-B08-5-R-01_0075_519910_to_529146\",\n",
    "    \"STT_CS-D-2014-MD-B02-3-R-04_0059_500764_to_510674\" : \"STT_CS-D-2014-M-D-B02-3-R-04_0059_500764_to_510674\",\n",
    "    \"STT_CS-L-2018_2018_M_M-D_D-B05_B05-3_3-R_R-01B_0051_386910_to_393921\" : \"STT_CS-L-2018/2018-M/M-D/D-B05/B05-3/3-R/R-01B_0051_386910_to_393921\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01a_0076_1108999_to_1111919\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01a_0076_1108999_to_1111919\",\n",
    "    \"STT_CS-X-D-2015-M-D-B03-3-R-01_0094_724975_to_731404\" : \"STT_CS-X-2015-M-D-B03-3-R-01_0094_724975_to_731404\",\n",
    "    \"STT_CS-D-2014-MD-B02-3-R-04_0025_206226_to_215603\" : \"STT_CS-D-2014-M-D-B02-3-R-04_0025_206226_to_215603\",\n",
    "    \"STT_CS-L-2018_2018_M_M-D_D-B05_B05-3_3-R_R-01B_0061_473520_to_476322\" : \"STT_CS-L-2018/2018-M/M-D/D-B05/B05-3/3-R/R-01B_0061_473520_to_476322\",\n",
    "    \"STT_CS-L-2018_2018_M_M-D_D-B05_B05-3_3-R_R-01B_0117_885102_to_892189\" : \"STT_CS-L-2018/2018-M/M-D/D-B05/B05-3/3-R/R-01B_0117_885102_to_892189\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01b_0090_1032201_to_1039246\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01b_0090_1032201_to_1039246\",\n",
    "    \"STT_CS-L-2018_2018_M_M-D_D-B05_B05-3_3-R_R-01B_0125_943962_to_950205\" : \"STT_CS-L-2018/2018-M/M-D/D-B05/B05-3/3-R/R-01B_0125_943962_to_950205\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01c_0043_757282_to_762302\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01c_0043_757282_to_762302\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01c_0027_552377_to_557575\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01c_0027_552377_to_557575\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01c_0063_1041634_to_1050072\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01c_0063_1041634_to_1050072\",\n",
    "    \"STT_CS-2013-P-D-B08-5-R-01_0012_79320_to_88112\" : \"STT_CS-D-2013-P-D-B08-5-R-01_0012_79320_to_88112\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01b_0053_717449_to_724502\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01b_0053_717449_to_724502\",\n",
    "    \"STT_CS-2013-P-D-B08-5-R-01_0086_624434_to_631074\" : \"STT_CS-D-2013-P-D-B08-5-R-01_0086_624434_to_631074\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01a_0051_541122_to_543299\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01a_0051_541122_to_543299\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01b_0144_2043840_to_2049342\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01b_0144_2043840_to_2049342\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01b_0076_891801_to_895260\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01b_0076_891801_to_895260\",\n",
    "    \"STT_CS-L-2018_2018_M_M-D_D-B05_B05-3_3-R_R-01B_0038_295557_to_300315\" : \"STT_CS-L-2018/2018-M/M-D/D-B05/B05-3/3-R/R-01B_0038_295557_to_300315\",\n",
    "    \"STT_CS-L-2018_2018_M_M-D_D-B05_B05-3_3-R_R-01B_0179_1424477_to_1431590\" : \"STT_CS-L-2018/2018-M/M-D/D-B05/B05-3/3-R/R-01B_0179_1424477_to_1431590\",\n",
    "    \"STT_CS-L-2018_2018_M_M-D_D-B05_B05-3_3-R_R-01B_0091_686356_to_692119\" : \"STT_CS-L-2018/2018-M/M-D/D-B05/B05-3/3-R/R-01B_0091_686356_to_692119\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01c_0065_1056704_to_1060264\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01c_0065_1056704_to_1060264\",\n",
    "    \"STT_CS-D-2014-MD-B02-3-R-04_0060_510674_to_520585\" : \"STT_CS-D-2014-M-D-B02-3-R-04_0060_510674_to_520585\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01a_0031_347954_to_354265\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01a_0031_347954_to_354265\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01c_0086_1255457_to_1262595\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01c_0086_1255457_to_1262595\",\n",
    "    \"STT_CS-D-2014-MD-B02-3-R-04_0011_86838_to_96195\" : \"STT_CS-D-2014-M-D-B02-3-R-04_0011_86838_to_96195\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01a_0023_236545_to_240240\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01a_0023_236545_to_240240\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01e_0029_511827_to_513902\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01e_0029_511827_to_513902\",\n",
    "    \"STT_CS-X-D-2015-M-D-B03-3-R-01_0120_910950_to_918615\" : \"STT_CS-X-2015-M-D-B03-3-R-01_0120_910950_to_918615\",\n",
    "    \"STT_CS-X-D-2015-M-D-B03-3-R-01_0112_857958_to_863130\" : \"STT_CS-X-2015-M-D-B03-3-R-01_0112_857958_to_863130\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01b_0016_180233_to_182865\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01b_0016_180233_to_182865\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01b_0044_649881_to_653138\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01b_0044_649881_to_653138\",\n",
    "    \"STT_CS-D-2014-MD-B02-3-R-04_0094_807696_to_817534\" : \"STT_CS-D-2014-M-D-B02-3-R-04_0094_807696_to_817534\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01c_0104_1419330_to_1421777\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01c_0104_1419330_to_1421777\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01b_0129_1798326_to_1801954\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01b_0129_1798326_to_1801954\",\n",
    "    \"STT_CS-X-D-2015-M-D-B03-3-R-01_0007_51274_to_53738\" : \"STT_CS-X-2015-M-D-B03-3-R-01_0007_51274_to_53738\",\n",
    "    \"STT_CS-X2019_X2019-M_P-D_D-02##_02##-0_0-Y_Y-01d_0011_139277_to_141741\" : \"STT_CS-L-2019/2019-M/P-D/D-B02/B02-0/0-Y/Y-01d_0011_139277_to_141741\",\n",
    "    \"STT_CS-2013-P-D-B08-5-R-01_0091_661812_to_670367\" : \"STT_CS-D-2013-P-D-B08-5-R-01_0091_661812_to_670367\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cs_file_name(code):\n",
    "    \n",
    "    try:\n",
    "        if code in file_name_correction:\n",
    "            code = file_name_correction[code]\n",
    "        # Split the code into parts\n",
    "        parts = code.split('-')\n",
    "\n",
    "        # Decode each part of the code\n",
    "        \n",
    "        data_type = {'X': 'non-designated', 'D': 'story-telling', 'L':'conversation'}.get(parts[1], 'Unknown')\n",
    "        birth_year = parts[2][:4]\n",
    "        gender = {'P': 'male', 'M': 'female', 'X': 'other'}.get(parts[3][:1], 'Unknown')\n",
    "        location = {'D': 'Dharamsala', 'S': 'South India', 'L': 'Ladakh', 'N': 'Nepal'}.get(parts[4][:1], 'Unknown')\n",
    "        education_type = parts[5][0]\n",
    "        education_years = parts[5][1:3]\n",
    "        grade_level = parts[6][:1]\n",
    "        school_code = parts[7][:1]\n",
    "\n",
    "        # Create a dictionary with the decoded values\n",
    "        decoded = {\n",
    "            'data_type': data_type,\n",
    "            'birth_year': int(birth_year),\n",
    "            'age': 2023 - int(birth_year),\n",
    "            'gender': gender,\n",
    "            'location': location,\n",
    "            'education_type': education_type,\n",
    "            'education_years': int(education_years),\n",
    "            'grade_level': int(grade_level),\n",
    "            'school_code': school_code\n",
    "        }\n",
    "    except:\n",
    "        print(f'Error decoding {code}')\n",
    "        return {}\n",
    "    return decoded\n",
    "\n",
    "# Example usage\n",
    "codes = [\n",
    "    'STT_CS-D-2016-M-D-B04-1-R-06_0017_147090_to_156979',\n",
    "    'STT_CS-X-2014-M-D-B02-4-R-01_0110_1035711_to_1037787',\n",
    "    'STT_CS-L-2014/2014-P/P-D/D-B03/B06-5/5-R/R-01_0129_1106637_to_1112914.mp3',\n",
    "]\n",
    "\n",
    "for code in codes:\n",
    "    print(parse_cs_file_name(code))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed = df_cs['file_name'].apply(lambda x: pd.Series(parse_cs_file_name(x)))\n",
    "df_cs = pd.concat([df_cs, df_parsed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[['age', 'cer']].groupby('age').mean('cer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[['age', 'cer']].groupby('age').mean('cer').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[['age', 'file_name']].groupby('age').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[['gender', 'cer']].groupby('gender').mean('cer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grade Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[['grade_level', 'file_name']].groupby('grade_level').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[['grade_level', 'cer']].groupby('grade_level').mean('cer').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### School Code\n",
    "School Code is which school the subject's data was collected from\n",
    "* R = རྡ་སྟེང་བོད་ཁྱིམ་སློབ་གྲྭ\n",
    "* B = བོད་ཁྱིམ་ཉིན་མོའི་སློབ་གྲྭ\n",
    "* D = དྷ་ཤོད་བོད་ཁྱིམ་སློབ་གྲྭ\n",
    "* Y = ཡོངས་གླིང་སློབ་གྲྭ\n",
    "* P = སྤོན་ཊ་སློབ་གྲྭ\n",
    "* S = ཤེས་རབ་དགའ་ཚལ་སློབ་གླིང་།\n",
    "* M = མན་ཇུ་ཤི་རི།\n",
    "* G = གོ་པལ་པུར་སློབ་གྲྭ\n",
    "* T = སམ་བྷོ་ཊ་སློབ་གྲྭ\n",
    "* Z = སུ་ཇཱ་སློབ་གྲྭ\n",
    "* C = ཅོན་ཏ་ར་བོད་ཁྱིམ་སློབ་གྲྭ\n",
    "* K = རྒྱུད་སྟོད་གྲྭ་ཚང་།\n",
    "* N = རྣམ་རྒྱལ་གྲྭ་ཚང་།\n",
    "* A = ཤུག་གསེབ་ཨ་ནེའི་དགོན་པ།\n",
    "* L = དགེ་ལྡན་ཆོས་གླིང་།\n",
    "* X = མེད་པ།"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[['school_code', 'cer']].groupby('school_code').mean('cer').plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[['school_code', 'cer']].groupby('school_code').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[['education_years', 'cer']].groupby('education_years').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[['education_years', 'cer']].groupby('education_years').mean('cer').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[['education_type', 'cer']].groupby('education_type').mean('cer').plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[['education_type', 'cer']].groupby('education_type').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import gradio as gr\n",
    "\n",
    "pipe = pipeline(model=\"spsither/whipser-small-r3-aug-length-penalty_n1\")  # change to \"your-username/the-name-you-picked\"\n",
    "\n",
    "def transcribe(audio):\n",
    "    text = pipe(audio)[\"text\"]\n",
    "    return text\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=gr.Audio(source=\"microphone\", type=\"filepath\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Whisper Large Tibetan\",\n",
    "    description=\"Realtime demo for Tibetan speech recognition using a fine-tuned Whisper medium model.\",\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse more in stt.pecha.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs['transcript'] = df_cs['inf']\n",
    "df_cs['reviewed_transcript'] = df_cs['uni']\n",
    "df_cs['inference_transcript'] = ''\n",
    "df_cs['group_id'] = 1\n",
    "df_cs['state'] = \"accepted\"\n",
    "df_cs['audio_duration'] = df_cs['cer']\n",
    "df_cs['transcriber_id'] = 1\n",
    "df_cs['reviewer_id'] = 2\n",
    "df_cs['final_reviewer_id'] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[df_cs['cer'] > 0.9].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['cer'] > 0.9][['url', 'uni', 'inf', 'cer']].to_csv('cer-0.9.tsv', sep='\\t', index=False)\n",
    "\n",
    "df_cs[df_cs['cer'] > 0.9][['file_name','url','inference_transcript','transcript','reviewed_transcript','audio_duration','group_id','state','transcriber_id','reviewer_id','final_reviewer_id']].to_csv('cer-0.9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[df_cs['cer'] > 0.8]['file_name'].to_csv('cer-0.9.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[df_cs['cer'] > 0.8][['file_name','url','transcript','reviewed_transcript']].to_csv('cer-0.9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[df_cs['cer'] < 0.1][['url', 'uni', 'inf', 'cer']].to_csv('cer-0.1.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs[df_cs['file_name'].isin([\n",
    "    'STT_TT00144_01232.950-01234.050',\n",
    "    \n",
    "    'STT_CS-D-2014-M-D-B01-3-R-03_0019_136172_to_139547',\n",
    "    'STT_CS-L-2017_2017-P_P-D_D-B01_B01-1_1-R_R-03_0139_1611503_to_1621020',\n",
    "    'STT_CS-D-2012-P-D-B04-5-R-01_0086_736163_to_745697',\n",
    "    \n",
    "    'STT_AB00233_0315_3763228_to_3772352',\n",
    "    'STT_AB00250_0191_1536177_to_1548643',\n",
    "    'STT_AB00255_0197_1588506_to_1600406'\n",
    "    \n",
    "    'STT_MV0081_0176_1408521_to_1412238',\n",
    "    'STT_MV0008_0130_957881_to_967209',\n",
    "])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/byt5-base\")\n",
    "\n",
    "input_ids_prompt = \"ཞུ་དག་བཏང་བྱས་བསམ་བློ་བཏང་ཡ་དེ་དཔེ་གལ་ཆེན་པོ་རེད།\"\n",
    "\n",
    "# input_ids_prompt = \"The dog chases a ball in the park.\"\n",
    "input_ids = tokenizer(input_ids_prompt).input_ids\n",
    "\n",
    "# Note that we cannot add \"{extra_id_...}\" to the string directly\n",
    "# as the Byte tokenizer would incorrectly merge the tokens\n",
    "# For ByT5, we need to work directly on the character level\n",
    "# Contrary to T5, ByT5 does not use sentinel tokens for masking, but instead\n",
    "# uses final utf character ids.\n",
    "# UTF-8 is represented by 8 bits and ByT5 has 3 special tokens.\n",
    "# => There are 2**8+2 = 259 input ids and mask tokens count down from index 258.\n",
    "# => mask to \"The dog [258]a ball [257]park.\"\n",
    "\n",
    "print(len(input_ids), len(input_ids_prompt))\n",
    "# print([input_ids[:8] + [258] + input_ids[14:]])\n",
    "\n",
    "print(input_ids_prompt)\n",
    "\n",
    "start = 56\n",
    "end = start + 10\n",
    "\n",
    "print(tokenizer.batch_decode([input_ids[:start] + [258] + input_ids[end:] ])[0])\n",
    "input_ids = torch.tensor([input_ids[:start] + [258] + input_ids[end:] ])\n",
    "\n",
    "\n",
    "# ByT5 produces only one char at a time so we need to produce many more output characters here -> set `max_length=100`.\n",
    "output_ids = model.generate(input_ids, max_length=100)[0].tolist()\n",
    "# print(output_ids)\n",
    "\n",
    "# ^- Note how 258 descends to 257, 256, 255\n",
    "\n",
    "# Now we need to split on the sentinel tokens, let's write a short loop for this\n",
    "output_ids_list = []\n",
    "start_token = 0\n",
    "sentinel_token = 258\n",
    "while sentinel_token in output_ids:\n",
    "    split_idx = output_ids.index(sentinel_token)\n",
    "    output_ids_list.append(output_ids[start_token:split_idx])\n",
    "    start_token = split_idx\n",
    "    sentinel_token -= 1\n",
    "\n",
    "output_ids_list.append(output_ids[start_token:])\n",
    "output_string = tokenizer.batch_decode(output_ids_list)\n",
    "output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\"ཞུ་\")\n",
    "test = \"ཞུ་\"\n",
    "len(tokenizer(test).input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"30097,STT_AB00233_0315_3763228_to_3772352,https://d38pmlk0v88drf.cloudfront.net/wav/STT_AB00233_0315_3763228_to_3772352.wav,,ན་ཏེ། སྤྱིར་ཁྲི་སྲོང་ལྟ་བུ་མངའ་ཐང་འདི་དུས་ལས་རྒྱ་ཆེ་ཡང་གདུང་རྒྱུད་གོང་མ་རྣམས་ཀྱིས་དབང་བའི་ཆབ་སྲིད་ཆེན་པོ་སྔར་ཡོད་ཀྱི་སྟེང་དུ། དཔུང་སྟོབས་ལྷག་པར་དར་བ་ཙམ་ཡིན་ལ། རྒྱལ་པོ་འདི་ནི་ཐོག་མར་ཡུལ་ཕྲན་འགའ་ཞིག་གི་བདག་པོ་ཙམ་དུ་བཞུགས་པ་ལས། ཡུན་ཐུང་ངུ་དེ་ཙམ་ཞིག་གི་རིང་ལ། ལེ་བར་ཁྲི་ཕྲག་དུ་མས་འཁྱུད་པའི་སའི་ཁྱོན་ལ་མངའ་མཛད་པའི་ཕྱིར་རོ།།ཐེ་ཙུང་ནི་ཐང་གུར་གྱི་གོང་མའི་ཁྲོད་ན་སྟོབས་ཤུགས་ཀྱི་གྲགས་སྙན་ཅན་ཡིན་མོད་ཀྱི། དེ་ཡང་དོན་ལ་བོད་ཀྱི་དཔུང་གི་རྔམས་ཟིལ་མ་བཟོད་པའི་ཁར། སྔར་སྲས་མོ་མི་སྟེར་བའི་ཁ་ཆད་བྱས་པ་ལ་བརྩིས་ཏེ། རེ་ཞིག་འཐབ་པའི་ཁུལ་དུ་བྱས་ཤིང་། བོད་དམག་ལ་ཉམ་ཉེས་པ་ཅུང་ཟད་བྱུང་བའི་མཇུག་ཏུ། ཀོང་ཇོ་ཡང་དེ་མ་ཐག་གནང་བ་ཡིན་ནོ་ཞེས་མཁས་པ་འགའ་ཞིག་གིས་ཟེར་ཏེ། ཤིན་ཏུ་བདེན་པར་འཁུམས་ཤིང་། ཐེ་ཙུང་ནས་བཟུང་རྒྱའི་མཁར་མིག་སུམ་བརྒྱ་ཙམ་བོད་ཀྱི་ལག་ཏུ་ཤོར་ཞེས་ཟེར་རོ། གཡོ་མེད་སྙིང་རྗེའི་དབང་ཕྱུག་སྤྱན་རས་གཟིགས།། ཡུད་ཙམ་ཁྲོས་པའི་སྤྱན་གྱི་སྡང་མིག་གིས།། གསེར་འབྲུག་སྡེར་ལྔའི་ཁྲི་ལ་འགྱིངས་པ་ཡི།། མཐུ་ལྡན་གནམ་གྱི་བུ་ཡང་འདར་བར་བྱས།། ཞེས་བྱ་བ་ནི་རྒྱལ་པོ་སྲོང་བཙན་སྒམ་པོའི་སྐབས་སོ། སྲོང་ ,པའི་ཆེད་དུ་གོང་ནས་དམག་བྟོན་མཛེངས་ཞན་ཐད་མཐུ་དགོང་རྩའ་ཡུན་གཉིས།ལན་འབྱོར་དང་ཧྲང་སྦྱོར་དང་། པུ་ཏིང་ཁེམ་ལ་དམག་དཔོན་,0,1,accepted,1,1,2\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
